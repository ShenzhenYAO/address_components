{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Key steps:\n",
    "\n",
    "1. Set data paths\n",
    "2. PyTorch setting\n",
    "3. Determine the device (i.e., cpu or cuda)\n",
    "4. Encoding data\n",
    "5. Split training, validation, and evaluation sets\n",
    "6. Building and training model\n",
    "7. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_version = \"test_v4.0\"\n",
    "\n",
    "\n",
    "# data file path\n",
    "input_filename = '<your source data file>.json.gz'\n",
    "project_data_path = r\"<your project path>\" # \n",
    "input_data_path = f\"{project_data_path}/data/out/shared_across_models/{input_filename}\"\n",
    "\n",
    "tag_pool_file_path = f'<your path to the tag pool file>.json'\n",
    "\n",
    "# Set the output directory where processed data will be saved\n",
    "output_path = f\"{project_data_path}/data/out/bi_lstm/{test_version}/\"\n",
    "output_encoded_path = f\"{output_path}/encoded\"\n",
    "output_models_path = f'{output_path}/models'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. PyTorch setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]= \":16:8\"\n",
    "import torch\n",
    "\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Determine the device (i.e., cpu or cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Check how many GPUs are available\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "    \n",
    "    # Find the GPU with the largest VRAM\n",
    "    max_vram = 0\n",
    "    selected_gpu = 0\n",
    "    for i in range(num_gpus):\n",
    "        vram = torch.cuda.get_device_properties(i).total_memory / (1024 ** 3)  # Convert to GB\n",
    "        print(f\"GPU {i}: {vram:.2f} GB of VRAM\")\n",
    "        if vram > max_vram:\n",
    "            max_vram = vram\n",
    "            selected_gpu = i\n",
    "\n",
    "    # Select the GPU with the largest VRAM\n",
    "    device = torch.device(f\"cuda:{selected_gpu}\")\n",
    "    print(f\"Selected GPU {selected_gpu} with {max_vram:.2f} GB of VRAM\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Encoding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "# import torch\n",
    "import tarfile\n",
    "import shutil\n",
    "from typing import Dict\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class BiLSTMAddressEncoder:\n",
    "    def __init__(self, config: Dict):\n",
    "        self.input_data_path = config[\"input_data_path\"]\n",
    "        self.output_encoded_path = config[\"output_encoded_path\"]\n",
    "\n",
    "        os.makedirs(self.output_encoded_path, exist_ok=True)\n",
    "        self.temp_dir = os.path.join(self.output_encoded_path, \"temp_dir\")\n",
    "        os.makedirs(self.temp_dir, exist_ok=True)\n",
    "\n",
    "        self.batch_size = config.get(\"batch_size\", 10000)\n",
    "        self.max_token_sequence_len = 0\n",
    "        self.tag_vocab_size = 0\n",
    "\n",
    "        self.maybe_tag_set = config.get('maybe_tag_set', set([\n",
    "                \"unit_designator\", \"unit_number\", \"unit_number_suffix\", \n",
    "                \"civic_number\", \"civic_number_suffix\", \n",
    "                \"street_name\", \"street_type\", \"street_direction\", \"street_qualifier\", \n",
    "                \"locality_name\", \"locality_type\", \n",
    "                \"province_code\"\n",
    "            ]))\n",
    "\n",
    "        self.token_vocab = {}\n",
    "        self.lemma_vocab = {}\n",
    "        self.tag_vocab = []\n",
    "        self.tag_to_id = {}\n",
    "        self.data = []\n",
    "\n",
    "    def load_data(self):\n",
    "        open_fn = open\n",
    "        if self.input_data_path.endswith(\".gz\"):\n",
    "            import gzip\n",
    "            open_fn = gzip.open\n",
    "        with open_fn(self.input_data_path, \"rt\", encoding=\"utf-8\") as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "    def normalize(self, text):\n",
    "        if text.isdigit():\n",
    "            return \"__num__\"\n",
    "        elif any(c.isalpha() for c in text) and any(c.isdigit() for c in text):\n",
    "            return \"__alnum__\"\n",
    "        return text\n",
    "\n",
    "    def build_vocabs(self):\n",
    "        tokens_set, lemmas_set, tags_set = set(), set(), set()\n",
    "\n",
    "        for item in self.data:\n",
    "            text = item[\"text\"]\n",
    "            self.max_token_sequence_len = max(self.max_token_sequence_len, len(item[\"tokens\"]))\n",
    "            for tok in item[\"tokens\"]:\n",
    "                word = self.normalize(text[tok[\"start\"]:tok[\"end\"]].lower())\n",
    "                lemma = self.normalize(tok.get(\"_lemma\", word).lower())\n",
    "                tokens_set.add(word)\n",
    "                lemmas_set.add(lemma)\n",
    "\n",
    "                std_tags = [t for t in tok.get(\"tags_std\", []) if t != \"none\"]\n",
    "                maybe_tags = [t for t in tok.get(\"tags_maybe\", []) if t != \"none\"]\n",
    "                tags_set.update(std_tags)\n",
    "                tags_set.update(maybe_tags)\n",
    "\n",
    "        self.token_vocab = {tok: i + 1 for i, tok in enumerate(sorted(tokens_set))}\n",
    "        self.lemma_vocab = {lem: i + 1 for i, lem in enumerate(sorted(lemmas_set))}\n",
    "        self.tag_vocab = sorted(tags_set)\n",
    "        self.tag_to_id = {tag: i for i, tag in enumerate(self.tag_vocab)}\n",
    "        self.tag_vocab_size = len(self.tag_vocab)\n",
    "\n",
    "    def compute_num_prev_maybe_tags(self, tokens):\n",
    "\n",
    "        result = []\n",
    "        count = 0\n",
    "        for tok in tokens:\n",
    "            result.append(count)\n",
    "            if any(tag in self.maybe_tag_set for tag in tok.get(\"tags_maybe\", []) if tag != \"none\"):\n",
    "                count += 1\n",
    "        return result\n",
    "\n",
    "    def compute_num_next_maybe_tags(self, tokens):\n",
    "        result = []\n",
    "        count = 0\n",
    "        for i in reversed(range(len(tokens))):\n",
    "            result.insert(0, count)\n",
    "            if any(tag in self.maybe_tag_set for tag in tokens[i].get(\"tags_maybe\", []) if tag != \"none\"):\n",
    "                count += 1\n",
    "        return result\n",
    "    \n",
    "    def compute_distance_to_prev_maybe_tag(self, tokens):\n",
    "        result = []\n",
    "        last_index = -1\n",
    "        for i, tok in enumerate(tokens):\n",
    "            if last_index == -1:\n",
    "                result.append(-1)\n",
    "            else:\n",
    "                result.append(i - last_index)\n",
    "            if any(tag in self.maybe_tag_set for tag in tok.get(\"tags_maybe\", []) if tag != \"none\"):\n",
    "                last_index = i\n",
    "        return result\n",
    "\n",
    "    def compute_distance_to_next_maybe_tag(self, tokens):\n",
    "        result = [-1] * len(tokens)\n",
    "        next_index = -1\n",
    "        for i in reversed(range(len(tokens))):\n",
    "            if next_index == -1:\n",
    "                result[i] = -1\n",
    "            else:\n",
    "                result[i] = next_index - i\n",
    "            if any(tag in self.maybe_tag_set for tag in tokens[i].get(\"tags_maybe\", []) if tag != \"none\"):\n",
    "                next_index = i\n",
    "        return result\n",
    "\n",
    "\n",
    "    def encode_and_save_dataset(self):\n",
    "        num_batches = (len(self.data) + self.batch_size - 1) // self.batch_size\n",
    "        dataset = []\n",
    "\n",
    "        for batch_idx in tqdm(range(num_batches), desc=\"Encoding batches\"):\n",
    "            batch = self.data[batch_idx * self.batch_size:(batch_idx + 1) * self.batch_size]\n",
    "\n",
    "            for i, item in enumerate(batch):\n",
    "                global_index = batch_idx * self.batch_size + i\n",
    "\n",
    "                text = item[\"text\"]\n",
    "                tokens = item[\"tokens\"]\n",
    "                s, l, m, le = [], [], [], []\n",
    "\n",
    "                prev_maybe_counts = self.compute_num_prev_maybe_tags(tokens)\n",
    "                next_maybe_counts = self.compute_num_next_maybe_tags(tokens)\n",
    "                dist_to_prev = self.compute_distance_to_prev_maybe_tag(tokens)\n",
    "                dist_to_next = self.compute_distance_to_next_maybe_tag(tokens)\n",
    "\n",
    "                for j, tok in enumerate(tokens):\n",
    "                    word_raw = text[tok[\"start\"]:tok[\"end\"]].lower()\n",
    "                    lemma_raw = tok.get(\"_lemma\", word_raw).lower()\n",
    "\n",
    "                    word = self.normalize(word_raw)\n",
    "                    lemma = self.normalize(lemma_raw)\n",
    "\n",
    "                    s.append(self.token_vocab.get(word, 0))\n",
    "                    le.append(self.lemma_vocab.get(lemma, 0))\n",
    "\n",
    "                    std_tags = [t for t in tok.get(\"tags_std\", []) if t != \"none\"]\n",
    "                    maybe_tags = [t for t in tok.get(\"tags_maybe\", []) if t != \"none\"]\n",
    "\n",
    "                    label = self.tag_to_id.get(std_tags[0], -100) if std_tags else -100\n",
    "                    l.append(label)\n",
    "\n",
    "                    tag_counts = Counter(maybe_tags)\n",
    "                    total = sum(tag_counts.values())\n",
    "                    maybe_vec = [\n",
    "                        tag_counts.get(tag, 0) / total if total > 0 else 0.0\n",
    "                        for tag in self.tag_vocab\n",
    "                    ]\n",
    "                    m.append(maybe_vec)\n",
    "\n",
    "                pad_len = self.max_token_sequence_len - len(s)\n",
    "                record = {\n",
    "                    \"sequences\": s + [0] * pad_len,\n",
    "                    \"labels\": l + [-100] * pad_len,\n",
    "                    \"tags_maybe_features\": m + [[0.0] * self.tag_vocab_size for _ in range(pad_len)],\n",
    "                    \"lemma_features\": le + [0] * pad_len,\n",
    "                    \"prev_maybe_counts\": prev_maybe_counts + [-1] * pad_len,\n",
    "                    \"next_maybe_counts\": next_maybe_counts + [-1] * pad_len,\n",
    "                    \"distance_to_prev_maybe\": dist_to_prev + [-1] * pad_len,\n",
    "                    \"distance_to_next_maybe\": dist_to_next + [-1] * pad_len,\n",
    "                    \"original_index\": global_index\n",
    "                }\n",
    "                dataset.append(record)\n",
    "\n",
    "        dataset_pt_path = os.path.join(self.temp_dir, \"dataset.pt\")\n",
    "        torch.save(dataset, dataset_pt_path)\n",
    "\n",
    "        tar_path = os.path.join(self.output_encoded_path, \"dataset.tar.gz\")\n",
    "        with tarfile.open(tar_path, \"w:gz\") as tar:\n",
    "            tar.add(dataset_pt_path, arcname=\"dataset.pt\")\n",
    "\n",
    "\n",
    "    def save_metadata(self):\n",
    "        def dump_json(filename, obj):\n",
    "            path = os.path.join(self.output_encoded_path, filename)\n",
    "            with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(obj, f, ensure_ascii=False)\n",
    "\n",
    "        dump_json(\"tag_vocab.json\", self.tag_vocab)\n",
    "        dump_json(\"token_vocab.json\", self.token_vocab)\n",
    "        dump_json(\"lemma_vocab.json\", self.lemma_vocab)\n",
    "        dump_json(\"length_metadata.json\", {\n",
    "            \"max_token_sequence_len\": self.max_token_sequence_len,\n",
    "            \"tag_vocab_size\": self.tag_vocab_size,\n",
    "            \"token_vocab_size\": len(self.token_vocab),\n",
    "            \"lemma_vocab_size\": len(self.lemma_vocab)\n",
    "        })\n",
    "\n",
    "    def cleanup_temp_dir(self):\n",
    "        if os.path.exists(self.temp_dir):\n",
    "            shutil.rmtree(self.temp_dir)\n",
    "\n",
    "    def run(self):\n",
    "        self.load_data()\n",
    "        self.build_vocabs()\n",
    "        self.encode_and_save_dataset()\n",
    "        self.save_metadata()\n",
    "        self.cleanup_temp_dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"input_data_path\": input_data_path,\n",
    "    \"output_encoded_path\": output_encoded_path,\n",
    "    \"batch_size\": 10000,\n",
    "}\n",
    "encoder = BiLSTMAddressEncoder(config)\n",
    "encoder.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Split training, validation, and evaluation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "# import torch\n",
    "import random\n",
    "\n",
    "def split_and_save_dataset(\n",
    "    output_encoded_path,\n",
    "    seed=42,\n",
    "    split_ratio=(0.4, 0.3, 0.3),\n",
    "    input_dataset_name=\"dataset\",\n",
    "    output_dataset_names=(\"train\", \"valid\", \"eval\")\n",
    "):\n",
    "    assert sum(split_ratio) == 1.0, \"Split ratios must sum to 1.0\"\n",
    "    assert len(output_dataset_names) == 3, \"output_dataset_names must be a tuple of 3 strings\"\n",
    "\n",
    "    # Step 1: Extract dataset.pt from dataset.tar.gz\n",
    "    tar_path = os.path.join(output_encoded_path, f\"{input_dataset_name}.tar.gz\")\n",
    "    extract_dir = os.path.join(output_encoded_path, \"temp_extract\")\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "        tar.extract(f\"{input_dataset_name}.pt\", path=extract_dir)\n",
    "\n",
    "    dataset_path = os.path.join(extract_dir, f\"{input_dataset_name}.pt\")\n",
    "    dataset = torch.load(dataset_path)\n",
    "\n",
    "    # Step 2: Shuffle and split indices\n",
    "    total = len(dataset)\n",
    "    indices = list(range(total))\n",
    "    random.seed(seed)\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    n_train = int(split_ratio[0] * total)\n",
    "    n_eval = int(split_ratio[1] * total)\n",
    "    n_test = total - n_train - n_eval\n",
    "\n",
    "    split_indices = {\n",
    "        output_dataset_names[0]: indices[:n_train],\n",
    "        output_dataset_names[1]: indices[n_train:n_train + n_eval],\n",
    "        output_dataset_names[2]: indices[n_train + n_eval:]\n",
    "    }\n",
    "\n",
    "    # Step 3: Save each split\n",
    "    for name, index_list in split_indices.items():\n",
    "        subset = [dataset[i] for i in index_list]\n",
    "        temp_pt_path = os.path.join(output_encoded_path, f\"{name}.pt\")\n",
    "        torch.save(subset, temp_pt_path)\n",
    "\n",
    "        with tarfile.open(os.path.join(output_encoded_path, f\"{name}.tar.gz\"), \"w:gz\") as tar:\n",
    "            tar.add(temp_pt_path, arcname=f\"{input_dataset_name}.pt\")\n",
    "\n",
    "        os.remove(temp_pt_path)\n",
    "\n",
    "    # Step 4: Cleanup\n",
    "    os.remove(dataset_path)\n",
    "    os.rmdir(extract_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_and_save_dataset(\n",
    "    output_encoded_path=output_encoded_path,\n",
    "    seed=123,\n",
    "    # input_dataset_name = 'dataset',\n",
    "    # split_ratio=(0.5, 0.25, 0.25),\n",
    "    # dataset_names=(\"train_set\", \"validation_set\", \"test_set\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Building and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tarfile\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class BiLSTMMultiLabelTagger(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        token_vocab_size,\n",
    "        lemma_vocab_size,\n",
    "        tag_maybe_feature_dim,\n",
    "        tag_output_dim,\n",
    "        embedding_dim=128,\n",
    "        hidden_dim=256,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(token_vocab_size + 1, embedding_dim, padding_idx=0)\n",
    "        self.lemma_embedding = nn.Embedding(lemma_vocab_size + 1, embedding_dim, padding_idx=0)\n",
    "        self.input_dim = embedding_dim * 2 + tag_maybe_feature_dim\n",
    "        self.lstm = nn.LSTM(self.input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(hidden_dim * 2, tag_output_dim)\n",
    "\n",
    "    def forward(self, sequences, lemmas, tags_maybe_features):\n",
    "        tok_emb = self.token_embedding(sequences)\n",
    "        lem_emb = self.lemma_embedding(lemmas)\n",
    "        concat = torch.cat([tok_emb, lem_emb, tags_maybe_features], dim=-1)\n",
    "        lstm_out, _ = self.lstm(concat)\n",
    "        logits = self.classifier(self.dropout(lstm_out))\n",
    "        return logits\n",
    "\n",
    "\n",
    "class BiLSTMMultiLabelTrainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.output_encoded_path = config[\"output_encoded_path\"]\n",
    "        self.train_tar = os.path.join(self.output_encoded_path, \"train.tar.gz\")\n",
    "        self.valid_tar = os.path.join(self.output_encoded_path, \"valid.tar.gz\")\n",
    "        self.output_models_path = config[\"output_models_path\"]\n",
    "        os.makedirs(self.output_models_path, exist_ok=True)\n",
    "\n",
    "        self.device = config.get(\"device\", \"cpu\")\n",
    "        self.patience = config.get(\"early_stopping_patience\", 2)\n",
    "        self.min_delta = config.get(\"min_loss_delta\", 0.001)\n",
    "        self.min_train_loss = config.get(\"min_train_loss\", 0.00005)\n",
    "\n",
    "    def load_metadata(self):\n",
    "        with open(os.path.join(self.output_encoded_path, \"length_metadata.json\")) as f:\n",
    "            meta = json.load(f)\n",
    "        with open(os.path.join(self.output_encoded_path, \"tag_vocab.json\")) as f:\n",
    "            tag_vocab = json.load(f)\n",
    "\n",
    "        self.tag_output_dim = len(tag_vocab)\n",
    "        self.tag_maybe_feature_dim = self.tag_output_dim\n",
    "        self.token_vocab_size = meta[\"token_vocab_size\"]\n",
    "        self.lemma_vocab_size = meta[\"lemma_vocab_size\"]\n",
    "\n",
    "    def _load_dataset(self, tar_path):\n",
    "        extract_dir = os.path.join(self.output_encoded_path, \"temp_data\")\n",
    "        os.makedirs(extract_dir, exist_ok=True)\n",
    "        with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "            tar.extract(\"dataset.pt\", path=extract_dir)\n",
    "        data = torch.load(os.path.join(extract_dir, \"dataset.pt\"))\n",
    "        shutil.rmtree(extract_dir)\n",
    "        return data\n",
    "\n",
    "    def train(self, epochs=1000, batch_size=32, lr=1e-3, seed=42):\n",
    "        self.load_metadata()\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "\n",
    "        train_data = self._load_dataset(self.train_tar)\n",
    "        valid_data = self._load_dataset(self.valid_tar)\n",
    "\n",
    "        train_set = torch.utils.data.TensorDataset(\n",
    "            torch.tensor([d[\"sequences\"] for d in train_data], dtype=torch.long),\n",
    "            torch.tensor([d[\"lemma_features\"] for d in train_data], dtype=torch.long),\n",
    "            torch.tensor([d[\"tags_maybe_features\"] for d in train_data], dtype=torch.float),\n",
    "            torch.stack([self._labels_to_multihot(d[\"labels\"]) for d in train_data])\n",
    "        )\n",
    "        valid_set = torch.utils.data.TensorDataset(\n",
    "            torch.tensor([d[\"sequences\"] for d in valid_data], dtype=torch.long),\n",
    "            torch.tensor([d[\"lemma_features\"] for d in valid_data], dtype=torch.long),\n",
    "            torch.tensor([d[\"tags_maybe_features\"] for d in valid_data], dtype=torch.float),\n",
    "            torch.stack([self._labels_to_multihot(d[\"labels\"]) for d in valid_data])\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "        valid_loader = DataLoader(valid_set, batch_size=batch_size)\n",
    "\n",
    "        model = BiLSTMMultiLabelTagger(\n",
    "            token_vocab_size=self.token_vocab_size,\n",
    "            lemma_vocab_size=self.lemma_vocab_size,\n",
    "            tag_maybe_feature_dim=self.tag_maybe_feature_dim,\n",
    "            tag_output_dim=self.tag_output_dim\n",
    "        ).to(self.device)\n",
    "\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        best_val_loss = float(\"inf\")\n",
    "        prev_train_loss = float(\"inf\")\n",
    "        patience_counter = 0\n",
    "\n",
    "        min_train_loss = self.config.get(\"min_train_loss\", 0.00005)\n",
    "        min_delta = self.config.get(\"min_loss_delta\", 0.001)\n",
    "        min_train_delta = self.config.get(\"min_train_delta\", 0.001)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            total_train_loss = 0\n",
    "\n",
    "            for seqs, lems, feats, lbls in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "                seqs = seqs.to(self.device)\n",
    "                lems = lems.to(self.device)\n",
    "                feats = feats.to(self.device)\n",
    "                lbls = lbls.to(self.device)\n",
    "\n",
    "                logits = model(seqs, lems, feats)\n",
    "                loss = loss_fn(logits, lbls)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_train_loss += loss.item()\n",
    "\n",
    "            model.eval()\n",
    "            total_val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for seqs, lems, feats, lbls in tqdm(valid_loader, desc=f\"Epoch {epoch+1} [Valid]\"):\n",
    "                    seqs = seqs.to(self.device)\n",
    "                    lems = lems.to(self.device)\n",
    "                    feats = feats.to(self.device)\n",
    "                    lbls = lbls.to(self.device)\n",
    "\n",
    "                    logits = model(seqs, lems, feats)\n",
    "                    loss = loss_fn(logits, lbls)\n",
    "                    total_val_loss += loss.item()\n",
    "\n",
    "            train_improvement = prev_train_loss - total_train_loss\n",
    "            val_improvement = best_val_loss - total_val_loss\n",
    "\n",
    "            print(f\"Epoch {epoch+1} | Train Loss: {total_train_loss:.6f} | ΔTrain: {train_improvement:.6f} | Val Loss: {total_val_loss:.6f} | ΔVal: {val_improvement:.6f}\")\n",
    "\n",
    "            # Condition 1: train loss below minimum\n",
    "            if total_train_loss < min_train_loss:\n",
    "                print(f\"Early stopping: total_train_loss < min_train_loss ({min_train_loss})\")\n",
    "                self.save_model(model)\n",
    "                break\n",
    "\n",
    "            # Condition 2: validation loss improvement\n",
    "            if val_improvement >= min_delta:\n",
    "                best_val_loss = total_val_loss\n",
    "                patience_counter = 0\n",
    "                self.save_model(model)\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f\"Patience: {patience_counter}/{self.patience} (ΔVal < {min_delta})\")\n",
    "                if patience_counter >= self.patience:\n",
    "                    print(\"Early stopping: validation loss not improving\")\n",
    "                    break\n",
    "\n",
    "            # Condition 3: training loss improvement too small\n",
    "            if train_improvement < min_train_delta:\n",
    "                print(f\"Early stopping: training improvement ΔTrain < min_train_delta ({min_train_delta})\")\n",
    "                break\n",
    "\n",
    "            prev_train_loss = total_train_loss\n",
    "\n",
    "    def _labels_to_multihot(self, label_indices):\n",
    "        vec = torch.zeros((len(label_indices), self.tag_output_dim), dtype=torch.float)\n",
    "        for i, label in enumerate(label_indices):\n",
    "            if label != -100:\n",
    "                vec[i][label] = 1.0\n",
    "        return vec\n",
    "\n",
    "    def save_model(self, model):\n",
    "        model_path = os.path.join(self.output_models_path, \"model_after_train.pt\")\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        tar_path = os.path.join(self.output_models_path, \"model_after_train.tar.gz\")\n",
    "        with tarfile.open(tar_path, \"w:gz\") as tar:\n",
    "            tar.add(model_path, arcname=\"model_after_train.pt\")\n",
    "\n",
    "        os.remove(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"output_encoded_path\": output_encoded_path,\n",
    "    \"output_models_path\": output_models_path,\n",
    "    \"device\": device,\n",
    "}\n",
    "\n",
    "trainer = BiLSTMMultiLabelTrainer(config)\n",
    "trainer.train(epochs=1000, batch_size=64, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import spacy\n",
    "import csv\n",
    "from torch.nn.functional import sigmoid\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_infix_regex\n",
    "from rapidfuzz import process, fuzz\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "class BiLSTMAddressPredictor:\n",
    "    def __init__(self, config):\n",
    "        self.model = config[\"model\"]\n",
    "        self.tokenizer_path = config[\"tokenizer_path\"]\n",
    "        self.tag_vocab_path = config[\"tag_vocab_path\"]\n",
    "        self.sequence_length_path = config[\"sequence_length_path\"]\n",
    "        self.tag_pool_path = config[\"tag_pool_path\"]\n",
    "        self.device = config.get(\"device\", \"cpu\")\n",
    "        self.result_path = config[\"result_path\"]\n",
    "        self.use_fuzzy_tags = config.get(\"use_fuzzy_tags\", True)\n",
    "        self.threshold = config.get(\"threshold\", 0.5)\n",
    "\n",
    "        self._init_spacy()\n",
    "        self._load_metadata()\n",
    "\n",
    "    def _init_spacy(self):\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "        def custom_tokenizer(nlp):\n",
    "            infixes = [x for x in nlp.Defaults.infixes if \"-\" not in x and \"'\" not in x]\n",
    "            infixes += [\n",
    "                r\"(?<![a-zA-Z])-+|-(?![a-zA-Z])|(?<=[a-zA-Z])-{2,}(?=[a-zA-Z])\",\n",
    "                r\"(?<![a-zA-Z])'+|'(?![a-zA-Z])|(?<=[a-zA-Z])'{2,}(?=[a-zA-Z])\",\n",
    "                r\"[,\\.\\?\\(\\)\\[\\]\\+_#/&]\"\n",
    "            ]\n",
    "            return Tokenizer(nlp.vocab, infix_finditer=compile_infix_regex(infixes).finditer, token_match=None)\n",
    "\n",
    "        self.nlp.tokenizer = custom_tokenizer(self.nlp)\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        base_path = os.path.dirname(self.tag_vocab_path)\n",
    "\n",
    "        with open(self.tag_vocab_path) as f:\n",
    "            self.tag_vocab = json.load(f)\n",
    "        with open(self.sequence_length_path) as f:\n",
    "            meta = json.load(f)\n",
    "            self.max_token_sequence_len = meta[\"max_token_sequence_len\"]\n",
    "\n",
    "        with open(self.tag_pool_path) as f:\n",
    "            raw_pool = json.load(f)\n",
    "        self.tag_pool = defaultdict(Counter)\n",
    "        for entry in raw_pool:\n",
    "            tag = entry[\"tag\"]\n",
    "            if not tag.startswith(\"o_\") and \"_\" in tag:\n",
    "                clean_tag = tag.split(\"_\", 1)[-1]\n",
    "                self.tag_pool[entry[\"text\"].lower()][clean_tag] += 1\n",
    "\n",
    "        with open(os.path.join(base_path, \"token_vocab.json\")) as f:\n",
    "            self.token_vocab = json.load(f)\n",
    "        with open(os.path.join(base_path, \"lemma_vocab.json\")) as f:\n",
    "            self.lemma_vocab = json.load(f)\n",
    "\n",
    "        self.tag_to_id = {tag: i for i, tag in enumerate(self.tag_vocab)}\n",
    "        self.id_to_tag = {i: tag for tag, i in self.tag_to_id.items()}\n",
    "        self.tag_vocab_size = len(self.tag_vocab)\n",
    "\n",
    "    def predict(self, address_list):\n",
    "        self.address_list = address_list\n",
    "        self._tokenize()\n",
    "        self._add_tags_maybe()\n",
    "        self._encode()\n",
    "        self._predict_logits()\n",
    "        self._decode()\n",
    "        self.save_results()\n",
    "\n",
    "    def _tokenize(self):\n",
    "        self.tokenized = []\n",
    "        for address in self.address_list:\n",
    "            doc = self.nlp(address)\n",
    "            self.tokenized.append({\n",
    "                \"text\": address,\n",
    "                \"tokens\": [\n",
    "                    {\n",
    "                        \"_lemma\": tok.lemma_.lower(),\n",
    "                        \"start\": tok.idx,\n",
    "                        \"end\": tok.idx + len(tok),\n",
    "                    }\n",
    "                    for tok in doc\n",
    "                ]\n",
    "            })\n",
    "\n",
    "    def _add_tags_maybe(self):\n",
    "        self.tagged = []\n",
    "        for addr in self.tokenized:\n",
    "            for tok in addr[\"tokens\"]:\n",
    "                lemma = tok[\"_lemma\"]\n",
    "                tag_counts = self.tag_pool.get(lemma, {})\n",
    "                total = sum(tag_counts.values())\n",
    "                tag_probs = {tag: count / total for tag, count in tag_counts.items()} if total > 0 else {}\n",
    "\n",
    "                # Default tags for numeric/alphanumeric lemmas\n",
    "                if lemma.isdigit() or (any(c.isdigit() for c in lemma) and any(c.isalpha() for c in lemma)):\n",
    "                    for tag in [\"civic_number\", \"unit_number\", \"street_name\"]:\n",
    "                        tag_probs[tag] = max(tag_probs.get(tag, 0.0), 1.0)\n",
    "\n",
    "                # Fuzzy match if empty\n",
    "                if not tag_probs and self.use_fuzzy_tags:\n",
    "                    for t in self._fuzzy_match_tags(lemma):\n",
    "                        tag_probs[t] = 1.0\n",
    "\n",
    "                tok[\"tag_probs\"] = tag_probs if tag_probs else {\"none\": 1.0}\n",
    "            self.tagged.append(addr)\n",
    "\n",
    "    def _fuzzy_match_tags(self, token, threshold=90):\n",
    "        if not self.tag_pool:\n",
    "            return []\n",
    "        match, score, _ = process.extractOne(token, self.tag_pool.keys(), scorer=fuzz.ratio)\n",
    "        if score >= threshold:\n",
    "            return list(self.tag_pool[match].keys())\n",
    "        return []\n",
    "\n",
    "    def _encode(self):\n",
    "        self.encoded = []\n",
    "        for item in self.tagged:\n",
    "            tokens = item[\"tokens\"]\n",
    "            seq, lem, maybes = [], [], []\n",
    "            for tok in tokens:\n",
    "                word = item['text'][tok[\"start\"]:tok[\"end\"]].lower()\n",
    "                lemma = tok[\"_lemma\"]\n",
    "\n",
    "                if word.isdigit():\n",
    "                    word_norm = \"__num__\"\n",
    "                elif any(c.isdigit() for c in word) and any(c.isalpha() for c in word):\n",
    "                    word_norm = \"__alnum__\"\n",
    "                elif word in self.token_vocab:\n",
    "                    word_norm = word\n",
    "                else:\n",
    "                    word_norm = \"__unk__\"\n",
    "\n",
    "                if lemma.isdigit():\n",
    "                    lemma_norm = \"__num__\"\n",
    "                elif any(c.isdigit() for c in lemma) and any(c.isalpha() for c in lemma):\n",
    "                    lemma_norm = \"__alnum__\"\n",
    "                elif lemma in self.lemma_vocab:\n",
    "                    lemma_norm = lemma\n",
    "                else:\n",
    "                    lemma_norm = \"__unk__\"\n",
    "\n",
    "                seq.append(self.token_vocab.get(word_norm, 0))\n",
    "                lem.append(self.lemma_vocab.get(lemma_norm, 0))\n",
    "\n",
    "                maybe_vec = [0.0] * self.tag_vocab_size\n",
    "                for tag, prob in tok.get(\"tag_probs\", {}).items():\n",
    "                    if tag in self.tag_to_id:\n",
    "                        maybe_vec[self.tag_to_id[tag]] = float(prob)\n",
    "                maybes.append(maybe_vec)\n",
    "\n",
    "            pad_len = self.max_token_sequence_len - len(seq)\n",
    "            self.encoded.append({\n",
    "                \"sequences\": seq + [0] * pad_len,\n",
    "                \"lemmas\": lem + [0] * pad_len,\n",
    "                \"tags_maybe_features\": maybes + [[0.0] * self.tag_vocab_size] * pad_len,\n",
    "                \"valid_len\": len(seq)\n",
    "            })\n",
    "\n",
    "    def _predict_logits(self):\n",
    "        self.raw_logits = []\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for item in self.encoded:\n",
    "                seqs = torch.tensor([item[\"sequences\"]], dtype=torch.long).to(self.device)\n",
    "                lems = torch.tensor([item[\"lemmas\"]], dtype=torch.long).to(self.device)\n",
    "                maybes = torch.tensor([item[\"tags_maybe_features\"]], dtype=torch.float).to(self.device)\n",
    "\n",
    "                logits = self.model(seqs, lems, maybes)\n",
    "                probs = sigmoid(logits).squeeze(0).to(self.device)\n",
    "                self.raw_logits.append(probs)\n",
    "\n",
    "    def _decode(self):\n",
    "        self.results = []\n",
    "        self.token_level_outputs = []  # ⬅️ Store per-token prediction details\n",
    "\n",
    "        for i, item in enumerate(self.tagged):\n",
    "            tokens = item[\"tokens\"]\n",
    "            probs = self.raw_logits[i]\n",
    "            tag_map = {}\n",
    "            token_outputs = []\n",
    "\n",
    "            for j, token_probs in enumerate(probs):\n",
    "                if j >= len(tokens):\n",
    "                    continue\n",
    "                token_text = item['text'][tokens[j][\"start\"]:tokens[j][\"end\"]].lower()\n",
    "                max_prob, tag_idx = torch.max(token_probs, dim=0)\n",
    "                tag = self.id_to_tag.get(tag_idx.item())\n",
    "\n",
    "                token_info = {\n",
    "                    \"text\": token_text,\n",
    "                    \"start\": tokens[j][\"start\"],\n",
    "                    \"end\": tokens[j][\"end\"],\n",
    "                    \"predicted_tag\": tag,\n",
    "                    \"probability\": round(max_prob.item(), 4),\n",
    "                    \"all_probs\": {\n",
    "                        self.id_to_tag[k]: round(v.item(), 4)\n",
    "                        for k, v in enumerate(token_probs)\n",
    "                    }\n",
    "                }\n",
    "                token_outputs.append(token_info)\n",
    "\n",
    "                if max_prob.item() >= self.threshold and tag:\n",
    "                    tag_map.setdefault(tag, []).append(token_text)\n",
    "\n",
    "            tag_map[\"text\"] = item[\"text\"]\n",
    "            self.results.append(tag_map)\n",
    "            self.token_level_outputs.append(token_outputs)\n",
    "\n",
    "                \n",
    "    def save_results(self):\n",
    "        os.makedirs(self.result_path, exist_ok=True)\n",
    "\n",
    "        json_path = os.path.join(self.result_path, \"predicted_components.json\")\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        fixed_tags = [\n",
    "            \"unit_designator\", \"unit_number\", \"unit_number_suffix\", \n",
    "            \"civic_number\", \"civic_number_suffix\", \n",
    "            \"street_name\", \"street_type\", \"street_direction\", \"street_qualifier\", \n",
    "            \"locality_name\", \"locality_type\", \n",
    "            \"province_code\"\n",
    "        ]\n",
    "\n",
    "        csv_path = os.path.join(self.result_path, \"predicted_components.csv\")\n",
    "        with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"text\"] + fixed_tags)\n",
    "            for res in self.results:\n",
    "                row = [res[\"text\"]]\n",
    "                for tag in fixed_tags:\n",
    "                    row.append(\" \".join(res.get(tag, [])))\n",
    "                writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tarfile\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "def load_model_config_from_dataset_pt(output_encoded_path):\n",
    "    tar_path = os.path.join(output_encoded_path, \"dataset.tar.gz\")\n",
    "    extract_dir = os.path.join(output_encoded_path, \"temp_model_extract\")\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "        tar.extract(\"dataset.pt\", path=extract_dir)\n",
    "\n",
    "    dataset_path = os.path.join(extract_dir, \"dataset.pt\")\n",
    "    dataset = torch.load(dataset_path)  # This is a list of dicts\n",
    "\n",
    "    token_vocab_size = max(max(d[\"sequences\"]) for d in dataset)\n",
    "    lemma_vocab_size = max(max(d[\"lemma_features\"]) for d in dataset)\n",
    "    with open(os.path.join(output_encoded_path, \"tag_vocab.json\")) as f:\n",
    "        tag_vocab = json.load(f)\n",
    "    tag_maybe_feature_dim = len(tag_vocab)\n",
    "\n",
    "    shutil.rmtree(extract_dir)\n",
    "\n",
    "    return {\n",
    "        \"token_vocab_size\": token_vocab_size,\n",
    "        \"lemma_vocab_size\": lemma_vocab_size,\n",
    "        \"tag_maybe_feature_dim\": tag_maybe_feature_dim,\n",
    "        \"tag_output_dim\": tag_maybe_feature_dim  # same\n",
    "    }\n",
    "\n",
    "def load_trained_model(output_models_path, model_config, device=\"cpu\"):\n",
    "    tar_path = os.path.join(output_models_path, \"model_after_train.tar.gz\")\n",
    "    extract_dir = os.path.join(output_models_path, \"temp_model_load\")\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "        tar.extract(\"model_after_train.pt\", path=extract_dir)\n",
    "\n",
    "    model = BiLSTMMultiLabelTagger(**model_config)\n",
    "    model_path = os.path.join(extract_dir, \"model_after_train.pt\")\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    shutil.rmtree(extract_dir)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# 2. Define paths\n",
    "output_encoded_path = os.path.join(output_path, \"encoded\")\n",
    "output_models_path = os.path.join(output_path, \"models\")\n",
    "result_path = os.path.join(output_path, \"results\")\n",
    "\n",
    "# 3. Load model config from dataset.pt\n",
    "model_config = load_model_config_from_dataset_pt(output_encoded_path)\n",
    "\n",
    "# 4. Load trained model\n",
    "model = load_trained_model(output_models_path, model_config, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Input address list\n",
    "addresses=[\n",
    "    \"12040 Horseshoe Way, Richmond, BC\",\n",
    "    \"108 East Hastings Street, Vancouver, BC\"\n",
    "]\n",
    "\n",
    "\n",
    "# 2. Set up inference config\n",
    "inference_config = {\n",
    "    \"model\": model,\n",
    "    \"tokenizer_path\": None,\n",
    "    \"tag_vocab_path\": os.path.join(output_encoded_path, \"tag_vocab.json\"),\n",
    "    \"sequence_length_path\": os.path.join(output_encoded_path, \"length_metadata.json\"),\n",
    "    \"tag_pool_path\": tag_pool_file_path,\n",
    "    \"device\": device,\n",
    "    \"result_path\": result_path,\n",
    "    \"use_fuzzy_tags\": True,\n",
    "    \"threshold\": 0.5 ## threshold to determine whether to ignore the predicted component\n",
    "}\n",
    "\n",
    "# 3. Run prediction\n",
    "predictor = BiLSTMAddressPredictor(inference_config)\n",
    "predictor.predict(addresses)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ubuntu_2204_01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
